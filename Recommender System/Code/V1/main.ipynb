{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ishaanpaul/Desktop/Extras/Graph-Neural-Network/.venv/lib/python3.12/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:13: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import sentence_transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from torch_geometric.data import HeteroData\n",
    "from torch_geometric.transforms import RandomLinkSplit, ToUndirected\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch import nn, optim, Tensor\n",
    "\n",
    "from torch_geometric.utils import structured_negative_sampling\n",
    "from torch_geometric.nn.conv.gcn_conv import gcn_norm\n",
    "from torch_geometric.nn import LGConv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_path = '../Dataset/ml-latest-small/movies.csv'\n",
    "rating_path = '../Dataset/ml-latest-small/ratings.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = pd.read_csv(movie_path)\n",
    "ratings = pd.read_csv(rating_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movieId</th>\n",
       "      <th>title</th>\n",
       "      <th>genres</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Toy Story (1995)</td>\n",
       "      <td>Adventure|Animation|Children|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Jumanji (1995)</td>\n",
       "      <td>Adventure|Children|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Grumpier Old Men (1995)</td>\n",
       "      <td>Comedy|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Waiting to Exhale (1995)</td>\n",
       "      <td>Comedy|Drama|Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Father of the Bride Part II (1995)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9737</th>\n",
       "      <td>193581</td>\n",
       "      <td>Black Butler: Book of the Atlantic (2017)</td>\n",
       "      <td>Action|Animation|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9738</th>\n",
       "      <td>193583</td>\n",
       "      <td>No Game No Life: Zero (2017)</td>\n",
       "      <td>Animation|Comedy|Fantasy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9739</th>\n",
       "      <td>193585</td>\n",
       "      <td>Flint (2017)</td>\n",
       "      <td>Drama</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9740</th>\n",
       "      <td>193587</td>\n",
       "      <td>Bungo Stray Dogs: Dead Apple (2018)</td>\n",
       "      <td>Action|Animation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9741</th>\n",
       "      <td>193609</td>\n",
       "      <td>Andrew Dice Clay: Dice Rules (1991)</td>\n",
       "      <td>Comedy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9742 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      movieId                                      title  \\\n",
       "0           1                           Toy Story (1995)   \n",
       "1           2                             Jumanji (1995)   \n",
       "2           3                    Grumpier Old Men (1995)   \n",
       "3           4                   Waiting to Exhale (1995)   \n",
       "4           5         Father of the Bride Part II (1995)   \n",
       "...       ...                                        ...   \n",
       "9737   193581  Black Butler: Book of the Atlantic (2017)   \n",
       "9738   193583               No Game No Life: Zero (2017)   \n",
       "9739   193585                               Flint (2017)   \n",
       "9740   193587        Bungo Stray Dogs: Dead Apple (2018)   \n",
       "9741   193609        Andrew Dice Clay: Dice Rules (1991)   \n",
       "\n",
       "                                           genres  \n",
       "0     Adventure|Animation|Children|Comedy|Fantasy  \n",
       "1                      Adventure|Children|Fantasy  \n",
       "2                                  Comedy|Romance  \n",
       "3                            Comedy|Drama|Romance  \n",
       "4                                          Comedy  \n",
       "...                                           ...  \n",
       "9737              Action|Animation|Comedy|Fantasy  \n",
       "9738                     Animation|Comedy|Fantasy  \n",
       "9739                                        Drama  \n",
       "9740                             Action|Animation  \n",
       "9741                                       Comedy  \n",
       "\n",
       "[9742 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964981247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>4.0</td>\n",
       "      <td>964982224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>47</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964983815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>50</td>\n",
       "      <td>5.0</td>\n",
       "      <td>964982931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100831</th>\n",
       "      <td>610</td>\n",
       "      <td>166534</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1493848402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100832</th>\n",
       "      <td>610</td>\n",
       "      <td>168248</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1493850091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100833</th>\n",
       "      <td>610</td>\n",
       "      <td>168250</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1494273047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100834</th>\n",
       "      <td>610</td>\n",
       "      <td>168252</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1493846352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100835</th>\n",
       "      <td>610</td>\n",
       "      <td>170875</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1493846415</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100836 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        userId  movieId  rating   timestamp\n",
       "0            1        1     4.0   964982703\n",
       "1            1        3     4.0   964981247\n",
       "2            1        6     4.0   964982224\n",
       "3            1       47     5.0   964983815\n",
       "4            1       50     5.0   964982931\n",
       "...        ...      ...     ...         ...\n",
       "100831     610   166534     4.0  1493848402\n",
       "100832     610   168248     5.0  1493850091\n",
       "100833     610   168250     5.0  1494273047\n",
       "100834     610   168252     5.0  1493846352\n",
       "100835     610   170875     3.0  1493846415\n",
       "\n",
       "[100836 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings = ratings.loc[ratings['movieId'].isin(movies['movieId'].unique())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_mapping = {userid: i for i, userid in enumerate(ratings['userId'].unique())}\n",
    "item_mapping = {isbn: i for i, isbn in enumerate(ratings['movieId'].unique())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count users and items\n",
    "num_users = len(user_mapping)\n",
    "num_items = len(item_mapping)\n",
    "num_total = num_users + num_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "610"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9724"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 0,\n",
       " 2: 1,\n",
       " 3: 2,\n",
       " 4: 3,\n",
       " 5: 4,\n",
       " 6: 5,\n",
       " 7: 6,\n",
       " 8: 7,\n",
       " 9: 8,\n",
       " 10: 9,\n",
       " 11: 10,\n",
       " 12: 11,\n",
       " 13: 12,\n",
       " 14: 13,\n",
       " 15: 14,\n",
       " 16: 15,\n",
       " 17: 16,\n",
       " 18: 17,\n",
       " 19: 18,\n",
       " 20: 19,\n",
       " 21: 20,\n",
       " 22: 21,\n",
       " 23: 22,\n",
       " 24: 23,\n",
       " 25: 24,\n",
       " 26: 25,\n",
       " 27: 26,\n",
       " 28: 27,\n",
       " 29: 28,\n",
       " 30: 29,\n",
       " 31: 30,\n",
       " 32: 31,\n",
       " 33: 32,\n",
       " 34: 33,\n",
       " 35: 34,\n",
       " 36: 35,\n",
       " 37: 36,\n",
       " 38: 37,\n",
       " 39: 38,\n",
       " 40: 39,\n",
       " 41: 40,\n",
       " 42: 41,\n",
       " 43: 42,\n",
       " 44: 43,\n",
       " 45: 44,\n",
       " 46: 45,\n",
       " 47: 46,\n",
       " 48: 47,\n",
       " 49: 48,\n",
       " 50: 49,\n",
       " 51: 50,\n",
       " 52: 51,\n",
       " 53: 52,\n",
       " 54: 53,\n",
       " 55: 54,\n",
       " 56: 55,\n",
       " 57: 56,\n",
       " 58: 57,\n",
       " 59: 58,\n",
       " 60: 59,\n",
       " 61: 60,\n",
       " 62: 61,\n",
       " 63: 62,\n",
       " 64: 63,\n",
       " 65: 64,\n",
       " 66: 65,\n",
       " 67: 66,\n",
       " 68: 67,\n",
       " 69: 68,\n",
       " 70: 69,\n",
       " 71: 70,\n",
       " 72: 71,\n",
       " 73: 72,\n",
       " 74: 73,\n",
       " 75: 74,\n",
       " 76: 75,\n",
       " 77: 76,\n",
       " 78: 77,\n",
       " 79: 78,\n",
       " 80: 79,\n",
       " 81: 80,\n",
       " 82: 81,\n",
       " 83: 82,\n",
       " 84: 83,\n",
       " 85: 84,\n",
       " 86: 85,\n",
       " 87: 86,\n",
       " 88: 87,\n",
       " 89: 88,\n",
       " 90: 89,\n",
       " 91: 90,\n",
       " 92: 91,\n",
       " 93: 92,\n",
       " 94: 93,\n",
       " 95: 94,\n",
       " 96: 95,\n",
       " 97: 96,\n",
       " 98: 97,\n",
       " 99: 98,\n",
       " 100: 99,\n",
       " 101: 100,\n",
       " 102: 101,\n",
       " 103: 102,\n",
       " 104: 103,\n",
       " 105: 104,\n",
       " 106: 105,\n",
       " 107: 106,\n",
       " 108: 107,\n",
       " 109: 108,\n",
       " 110: 109,\n",
       " 111: 110,\n",
       " 112: 111,\n",
       " 113: 112,\n",
       " 114: 113,\n",
       " 115: 114,\n",
       " 116: 115,\n",
       " 117: 116,\n",
       " 118: 117,\n",
       " 119: 118,\n",
       " 120: 119,\n",
       " 121: 120,\n",
       " 122: 121,\n",
       " 123: 122,\n",
       " 124: 123,\n",
       " 125: 124,\n",
       " 126: 125,\n",
       " 127: 126,\n",
       " 128: 127,\n",
       " 129: 128,\n",
       " 130: 129,\n",
       " 131: 130,\n",
       " 132: 131,\n",
       " 133: 132,\n",
       " 134: 133,\n",
       " 135: 134,\n",
       " 136: 135,\n",
       " 137: 136,\n",
       " 138: 137,\n",
       " 139: 138,\n",
       " 140: 139,\n",
       " 141: 140,\n",
       " 142: 141,\n",
       " 143: 142,\n",
       " 144: 143,\n",
       " 145: 144,\n",
       " 146: 145,\n",
       " 147: 146,\n",
       " 148: 147,\n",
       " 149: 148,\n",
       " 150: 149,\n",
       " 151: 150,\n",
       " 152: 151,\n",
       " 153: 152,\n",
       " 154: 153,\n",
       " 155: 154,\n",
       " 156: 155,\n",
       " 157: 156,\n",
       " 158: 157,\n",
       " 159: 158,\n",
       " 160: 159,\n",
       " 161: 160,\n",
       " 162: 161,\n",
       " 163: 162,\n",
       " 164: 163,\n",
       " 165: 164,\n",
       " 166: 165,\n",
       " 167: 166,\n",
       " 168: 167,\n",
       " 169: 168,\n",
       " 170: 169,\n",
       " 171: 170,\n",
       " 172: 171,\n",
       " 173: 172,\n",
       " 174: 173,\n",
       " 175: 174,\n",
       " 176: 175,\n",
       " 177: 176,\n",
       " 178: 177,\n",
       " 179: 178,\n",
       " 180: 179,\n",
       " 181: 180,\n",
       " 182: 181,\n",
       " 183: 182,\n",
       " 184: 183,\n",
       " 185: 184,\n",
       " 186: 185,\n",
       " 187: 186,\n",
       " 188: 187,\n",
       " 189: 188,\n",
       " 190: 189,\n",
       " 191: 190,\n",
       " 192: 191,\n",
       " 193: 192,\n",
       " 194: 193,\n",
       " 195: 194,\n",
       " 196: 195,\n",
       " 197: 196,\n",
       " 198: 197,\n",
       " 199: 198,\n",
       " 200: 199,\n",
       " 201: 200,\n",
       " 202: 201,\n",
       " 203: 202,\n",
       " 204: 203,\n",
       " 205: 204,\n",
       " 206: 205,\n",
       " 207: 206,\n",
       " 208: 207,\n",
       " 209: 208,\n",
       " 210: 209,\n",
       " 211: 210,\n",
       " 212: 211,\n",
       " 213: 212,\n",
       " 214: 213,\n",
       " 215: 214,\n",
       " 216: 215,\n",
       " 217: 216,\n",
       " 218: 217,\n",
       " 219: 218,\n",
       " 220: 219,\n",
       " 221: 220,\n",
       " 222: 221,\n",
       " 223: 222,\n",
       " 224: 223,\n",
       " 225: 224,\n",
       " 226: 225,\n",
       " 227: 226,\n",
       " 228: 227,\n",
       " 229: 228,\n",
       " 230: 229,\n",
       " 231: 230,\n",
       " 232: 231,\n",
       " 233: 232,\n",
       " 234: 233,\n",
       " 235: 234,\n",
       " 236: 235,\n",
       " 237: 236,\n",
       " 238: 237,\n",
       " 239: 238,\n",
       " 240: 239,\n",
       " 241: 240,\n",
       " 242: 241,\n",
       " 243: 242,\n",
       " 244: 243,\n",
       " 245: 244,\n",
       " 246: 245,\n",
       " 247: 246,\n",
       " 248: 247,\n",
       " 249: 248,\n",
       " 250: 249,\n",
       " 251: 250,\n",
       " 252: 251,\n",
       " 253: 252,\n",
       " 254: 253,\n",
       " 255: 254,\n",
       " 256: 255,\n",
       " 257: 256,\n",
       " 258: 257,\n",
       " 259: 258,\n",
       " 260: 259,\n",
       " 261: 260,\n",
       " 262: 261,\n",
       " 263: 262,\n",
       " 264: 263,\n",
       " 265: 264,\n",
       " 266: 265,\n",
       " 267: 266,\n",
       " 268: 267,\n",
       " 269: 268,\n",
       " 270: 269,\n",
       " 271: 270,\n",
       " 272: 271,\n",
       " 273: 272,\n",
       " 274: 273,\n",
       " 275: 274,\n",
       " 276: 275,\n",
       " 277: 276,\n",
       " 278: 277,\n",
       " 279: 278,\n",
       " 280: 279,\n",
       " 281: 280,\n",
       " 282: 281,\n",
       " 283: 282,\n",
       " 284: 283,\n",
       " 285: 284,\n",
       " 286: 285,\n",
       " 287: 286,\n",
       " 288: 287,\n",
       " 289: 288,\n",
       " 290: 289,\n",
       " 291: 290,\n",
       " 292: 291,\n",
       " 293: 292,\n",
       " 294: 293,\n",
       " 295: 294,\n",
       " 296: 295,\n",
       " 297: 296,\n",
       " 298: 297,\n",
       " 299: 298,\n",
       " 300: 299,\n",
       " 301: 300,\n",
       " 302: 301,\n",
       " 303: 302,\n",
       " 304: 303,\n",
       " 305: 304,\n",
       " 306: 305,\n",
       " 307: 306,\n",
       " 308: 307,\n",
       " 309: 308,\n",
       " 310: 309,\n",
       " 311: 310,\n",
       " 312: 311,\n",
       " 313: 312,\n",
       " 314: 313,\n",
       " 315: 314,\n",
       " 316: 315,\n",
       " 317: 316,\n",
       " 318: 317,\n",
       " 319: 318,\n",
       " 320: 319,\n",
       " 321: 320,\n",
       " 322: 321,\n",
       " 323: 322,\n",
       " 324: 323,\n",
       " 325: 324,\n",
       " 326: 325,\n",
       " 327: 326,\n",
       " 328: 327,\n",
       " 329: 328,\n",
       " 330: 329,\n",
       " 331: 330,\n",
       " 332: 331,\n",
       " 333: 332,\n",
       " 334: 333,\n",
       " 335: 334,\n",
       " 336: 335,\n",
       " 337: 336,\n",
       " 338: 337,\n",
       " 339: 338,\n",
       " 340: 339,\n",
       " 341: 340,\n",
       " 342: 341,\n",
       " 343: 342,\n",
       " 344: 343,\n",
       " 345: 344,\n",
       " 346: 345,\n",
       " 347: 346,\n",
       " 348: 347,\n",
       " 349: 348,\n",
       " 350: 349,\n",
       " 351: 350,\n",
       " 352: 351,\n",
       " 353: 352,\n",
       " 354: 353,\n",
       " 355: 354,\n",
       " 356: 355,\n",
       " 357: 356,\n",
       " 358: 357,\n",
       " 359: 358,\n",
       " 360: 359,\n",
       " 361: 360,\n",
       " 362: 361,\n",
       " 363: 362,\n",
       " 364: 363,\n",
       " 365: 364,\n",
       " 366: 365,\n",
       " 367: 366,\n",
       " 368: 367,\n",
       " 369: 368,\n",
       " 370: 369,\n",
       " 371: 370,\n",
       " 372: 371,\n",
       " 373: 372,\n",
       " 374: 373,\n",
       " 375: 374,\n",
       " 376: 375,\n",
       " 377: 376,\n",
       " 378: 377,\n",
       " 379: 378,\n",
       " 380: 379,\n",
       " 381: 380,\n",
       " 382: 381,\n",
       " 383: 382,\n",
       " 384: 383,\n",
       " 385: 384,\n",
       " 386: 385,\n",
       " 387: 386,\n",
       " 388: 387,\n",
       " 389: 388,\n",
       " 390: 389,\n",
       " 391: 390,\n",
       " 392: 391,\n",
       " 393: 392,\n",
       " 394: 393,\n",
       " 395: 394,\n",
       " 396: 395,\n",
       " 397: 396,\n",
       " 398: 397,\n",
       " 399: 398,\n",
       " 400: 399,\n",
       " 401: 400,\n",
       " 402: 401,\n",
       " 403: 402,\n",
       " 404: 403,\n",
       " 405: 404,\n",
       " 406: 405,\n",
       " 407: 406,\n",
       " 408: 407,\n",
       " 409: 408,\n",
       " 410: 409,\n",
       " 411: 410,\n",
       " 412: 411,\n",
       " 413: 412,\n",
       " 414: 413,\n",
       " 415: 414,\n",
       " 416: 415,\n",
       " 417: 416,\n",
       " 418: 417,\n",
       " 419: 418,\n",
       " 420: 419,\n",
       " 421: 420,\n",
       " 422: 421,\n",
       " 423: 422,\n",
       " 424: 423,\n",
       " 425: 424,\n",
       " 426: 425,\n",
       " 427: 426,\n",
       " 428: 427,\n",
       " 429: 428,\n",
       " 430: 429,\n",
       " 431: 430,\n",
       " 432: 431,\n",
       " 433: 432,\n",
       " 434: 433,\n",
       " 435: 434,\n",
       " 436: 435,\n",
       " 437: 436,\n",
       " 438: 437,\n",
       " 439: 438,\n",
       " 440: 439,\n",
       " 441: 440,\n",
       " 442: 441,\n",
       " 443: 442,\n",
       " 444: 443,\n",
       " 445: 444,\n",
       " 446: 445,\n",
       " 447: 446,\n",
       " 448: 447,\n",
       " 449: 448,\n",
       " 450: 449,\n",
       " 451: 450,\n",
       " 452: 451,\n",
       " 453: 452,\n",
       " 454: 453,\n",
       " 455: 454,\n",
       " 456: 455,\n",
       " 457: 456,\n",
       " 458: 457,\n",
       " 459: 458,\n",
       " 460: 459,\n",
       " 461: 460,\n",
       " 462: 461,\n",
       " 463: 462,\n",
       " 464: 463,\n",
       " 465: 464,\n",
       " 466: 465,\n",
       " 467: 466,\n",
       " 468: 467,\n",
       " 469: 468,\n",
       " 470: 469,\n",
       " 471: 470,\n",
       " 472: 471,\n",
       " 473: 472,\n",
       " 474: 473,\n",
       " 475: 474,\n",
       " 476: 475,\n",
       " 477: 476,\n",
       " 478: 477,\n",
       " 479: 478,\n",
       " 480: 479,\n",
       " 481: 480,\n",
       " 482: 481,\n",
       " 483: 482,\n",
       " 484: 483,\n",
       " 485: 484,\n",
       " 486: 485,\n",
       " 487: 486,\n",
       " 488: 487,\n",
       " 489: 488,\n",
       " 490: 489,\n",
       " 491: 490,\n",
       " 492: 491,\n",
       " 493: 492,\n",
       " 494: 493,\n",
       " 495: 494,\n",
       " 496: 495,\n",
       " 497: 496,\n",
       " 498: 497,\n",
       " 499: 498,\n",
       " 500: 499,\n",
       " 501: 500,\n",
       " 502: 501,\n",
       " 503: 502,\n",
       " 504: 503,\n",
       " 505: 504,\n",
       " 506: 505,\n",
       " 507: 506,\n",
       " 508: 507,\n",
       " 509: 508,\n",
       " 510: 509,\n",
       " 511: 510,\n",
       " 512: 511,\n",
       " 513: 512,\n",
       " 514: 513,\n",
       " 515: 514,\n",
       " 516: 515,\n",
       " 517: 516,\n",
       " 518: 517,\n",
       " 519: 518,\n",
       " 520: 519,\n",
       " 521: 520,\n",
       " 522: 521,\n",
       " 523: 522,\n",
       " 524: 523,\n",
       " 525: 524,\n",
       " 526: 525,\n",
       " 527: 526,\n",
       " 528: 527,\n",
       " 529: 528,\n",
       " 530: 529,\n",
       " 531: 530,\n",
       " 532: 531,\n",
       " 533: 532,\n",
       " 534: 533,\n",
       " 535: 534,\n",
       " 536: 535,\n",
       " 537: 536,\n",
       " 538: 537,\n",
       " 539: 538,\n",
       " 540: 539,\n",
       " 541: 540,\n",
       " 542: 541,\n",
       " 543: 542,\n",
       " 544: 543,\n",
       " 545: 544,\n",
       " 546: 545,\n",
       " 547: 546,\n",
       " 548: 547,\n",
       " 549: 548,\n",
       " 550: 549,\n",
       " 551: 550,\n",
       " 552: 551,\n",
       " 553: 552,\n",
       " 554: 553,\n",
       " 555: 554,\n",
       " 556: 555,\n",
       " 557: 556,\n",
       " 558: 557,\n",
       " 559: 558,\n",
       " 560: 559,\n",
       " 561: 560,\n",
       " 562: 561,\n",
       " 563: 562,\n",
       " 564: 563,\n",
       " 565: 564,\n",
       " 566: 565,\n",
       " 567: 566,\n",
       " 568: 567,\n",
       " 569: 568,\n",
       " 570: 569,\n",
       " 571: 570,\n",
       " 572: 571,\n",
       " 573: 572,\n",
       " 574: 573,\n",
       " 575: 574,\n",
       " 576: 575,\n",
       " 577: 576,\n",
       " 578: 577,\n",
       " 579: 578,\n",
       " 580: 579,\n",
       " 581: 580,\n",
       " 582: 581,\n",
       " 583: 582,\n",
       " 584: 583,\n",
       " 585: 584,\n",
       " 586: 585,\n",
       " 587: 586,\n",
       " 588: 587,\n",
       " 589: 588,\n",
       " 590: 589,\n",
       " 591: 590,\n",
       " 592: 591,\n",
       " 593: 592,\n",
       " 594: 593,\n",
       " 595: 594,\n",
       " 596: 595,\n",
       " 597: 596,\n",
       " 598: 597,\n",
       " 599: 598,\n",
       " 600: 599,\n",
       " 601: 600,\n",
       " 602: 601,\n",
       " 603: 602,\n",
       " 604: 603,\n",
       " 605: 604,\n",
       " 606: 605,\n",
       " 607: 606,\n",
       " 608: 607,\n",
       " 609: 608,\n",
       " 610: 609}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 0,\n",
       " 3: 1,\n",
       " 6: 2,\n",
       " 47: 3,\n",
       " 50: 4,\n",
       " 70: 5,\n",
       " 101: 6,\n",
       " 110: 7,\n",
       " 151: 8,\n",
       " 157: 9,\n",
       " 163: 10,\n",
       " 216: 11,\n",
       " 223: 12,\n",
       " 231: 13,\n",
       " 235: 14,\n",
       " 260: 15,\n",
       " 296: 16,\n",
       " 316: 17,\n",
       " 333: 18,\n",
       " 349: 19,\n",
       " 356: 20,\n",
       " 362: 21,\n",
       " 367: 22,\n",
       " 423: 23,\n",
       " 441: 24,\n",
       " 457: 25,\n",
       " 480: 26,\n",
       " 500: 27,\n",
       " 527: 28,\n",
       " 543: 29,\n",
       " 552: 30,\n",
       " 553: 31,\n",
       " 590: 32,\n",
       " 592: 33,\n",
       " 593: 34,\n",
       " 596: 35,\n",
       " 608: 36,\n",
       " 648: 37,\n",
       " 661: 38,\n",
       " 673: 39,\n",
       " 733: 40,\n",
       " 736: 41,\n",
       " 780: 42,\n",
       " 804: 43,\n",
       " 919: 44,\n",
       " 923: 45,\n",
       " 940: 46,\n",
       " 943: 47,\n",
       " 954: 48,\n",
       " 1009: 49,\n",
       " 1023: 50,\n",
       " 1024: 51,\n",
       " 1025: 52,\n",
       " 1029: 53,\n",
       " 1030: 54,\n",
       " 1031: 55,\n",
       " 1032: 56,\n",
       " 1042: 57,\n",
       " 1049: 58,\n",
       " 1060: 59,\n",
       " 1073: 60,\n",
       " 1080: 61,\n",
       " 1089: 62,\n",
       " 1090: 63,\n",
       " 1092: 64,\n",
       " 1097: 65,\n",
       " 1127: 66,\n",
       " 1136: 67,\n",
       " 1196: 68,\n",
       " 1197: 69,\n",
       " 1198: 70,\n",
       " 1206: 71,\n",
       " 1208: 72,\n",
       " 1210: 73,\n",
       " 1213: 74,\n",
       " 1214: 75,\n",
       " 1219: 76,\n",
       " 1220: 77,\n",
       " 1222: 78,\n",
       " 1224: 79,\n",
       " 1226: 80,\n",
       " 1240: 81,\n",
       " 1256: 82,\n",
       " 1258: 83,\n",
       " 1265: 84,\n",
       " 1270: 85,\n",
       " 1275: 86,\n",
       " 1278: 87,\n",
       " 1282: 88,\n",
       " 1291: 89,\n",
       " 1298: 90,\n",
       " 1348: 91,\n",
       " 1377: 92,\n",
       " 1396: 93,\n",
       " 1408: 94,\n",
       " 1445: 95,\n",
       " 1473: 96,\n",
       " 1500: 97,\n",
       " 1517: 98,\n",
       " 1552: 99,\n",
       " 1573: 100,\n",
       " 1580: 101,\n",
       " 1587: 102,\n",
       " 1617: 103,\n",
       " 1620: 104,\n",
       " 1625: 105,\n",
       " 1644: 106,\n",
       " 1676: 107,\n",
       " 1732: 108,\n",
       " 1777: 109,\n",
       " 1793: 110,\n",
       " 1804: 111,\n",
       " 1805: 112,\n",
       " 1920: 113,\n",
       " 1927: 114,\n",
       " 1954: 115,\n",
       " 1967: 116,\n",
       " 2000: 117,\n",
       " 2005: 118,\n",
       " 2012: 119,\n",
       " 2018: 120,\n",
       " 2028: 121,\n",
       " 2033: 122,\n",
       " 2046: 123,\n",
       " 2048: 124,\n",
       " 2054: 125,\n",
       " 2058: 126,\n",
       " 2078: 127,\n",
       " 2090: 128,\n",
       " 2093: 129,\n",
       " 2094: 130,\n",
       " 2096: 131,\n",
       " 2099: 132,\n",
       " 2105: 133,\n",
       " 2115: 134,\n",
       " 2116: 135,\n",
       " 2137: 136,\n",
       " 2139: 137,\n",
       " 2141: 138,\n",
       " 2143: 139,\n",
       " 2161: 140,\n",
       " 2174: 141,\n",
       " 2193: 142,\n",
       " 2253: 143,\n",
       " 2268: 144,\n",
       " 2273: 145,\n",
       " 2291: 146,\n",
       " 2329: 147,\n",
       " 2338: 148,\n",
       " 2353: 149,\n",
       " 2366: 150,\n",
       " 2387: 151,\n",
       " 2389: 152,\n",
       " 2395: 153,\n",
       " 2406: 154,\n",
       " 2414: 155,\n",
       " 2427: 156,\n",
       " 2450: 157,\n",
       " 2459: 158,\n",
       " 2470: 159,\n",
       " 2478: 160,\n",
       " 2492: 161,\n",
       " 2502: 162,\n",
       " 2528: 163,\n",
       " 2529: 164,\n",
       " 2542: 165,\n",
       " 2571: 166,\n",
       " 2580: 167,\n",
       " 2596: 168,\n",
       " 2616: 169,\n",
       " 2617: 170,\n",
       " 2628: 171,\n",
       " 2640: 172,\n",
       " 2641: 173,\n",
       " 2644: 174,\n",
       " 2648: 175,\n",
       " 2654: 176,\n",
       " 2657: 177,\n",
       " 2692: 178,\n",
       " 2700: 179,\n",
       " 2716: 180,\n",
       " 2761: 181,\n",
       " 2797: 182,\n",
       " 2826: 183,\n",
       " 2858: 184,\n",
       " 2872: 185,\n",
       " 2899: 186,\n",
       " 2916: 187,\n",
       " 2944: 188,\n",
       " 2947: 189,\n",
       " 2948: 190,\n",
       " 2949: 191,\n",
       " 2959: 192,\n",
       " 2985: 193,\n",
       " 2987: 194,\n",
       " 2991: 195,\n",
       " 2993: 196,\n",
       " 2997: 197,\n",
       " 3033: 198,\n",
       " 3034: 199,\n",
       " 3052: 200,\n",
       " 3053: 201,\n",
       " 3062: 202,\n",
       " 3147: 203,\n",
       " 3168: 204,\n",
       " 3176: 205,\n",
       " 3243: 206,\n",
       " 3247: 207,\n",
       " 3253: 208,\n",
       " 3273: 209,\n",
       " 3386: 210,\n",
       " 3439: 211,\n",
       " 3440: 212,\n",
       " 3441: 213,\n",
       " 3448: 214,\n",
       " 3450: 215,\n",
       " 3479: 216,\n",
       " 3489: 217,\n",
       " 3527: 218,\n",
       " 3578: 219,\n",
       " 3617: 220,\n",
       " 3639: 221,\n",
       " 3671: 222,\n",
       " 3702: 223,\n",
       " 3703: 224,\n",
       " 3729: 225,\n",
       " 3740: 226,\n",
       " 3744: 227,\n",
       " 3793: 228,\n",
       " 3809: 229,\n",
       " 4006: 230,\n",
       " 5060: 231,\n",
       " 318: 232,\n",
       " 1704: 233,\n",
       " 6874: 234,\n",
       " 8798: 235,\n",
       " 46970: 236,\n",
       " 48516: 237,\n",
       " 58559: 238,\n",
       " 60756: 239,\n",
       " 68157: 240,\n",
       " 71535: 241,\n",
       " 74458: 242,\n",
       " 77455: 243,\n",
       " 79132: 244,\n",
       " 80489: 245,\n",
       " 80906: 246,\n",
       " 86345: 247,\n",
       " 89774: 248,\n",
       " 91529: 249,\n",
       " 91658: 250,\n",
       " 99114: 251,\n",
       " 106782: 252,\n",
       " 109487: 253,\n",
       " 112552: 254,\n",
       " 114060: 255,\n",
       " 115713: 256,\n",
       " 122882: 257,\n",
       " 131724: 258,\n",
       " 31: 259,\n",
       " 647: 260,\n",
       " 688: 261,\n",
       " 720: 262,\n",
       " 849: 263,\n",
       " 914: 264,\n",
       " 1093: 265,\n",
       " 1124: 266,\n",
       " 1263: 267,\n",
       " 1272: 268,\n",
       " 1302: 269,\n",
       " 1371: 270,\n",
       " 2080: 271,\n",
       " 2288: 272,\n",
       " 2424: 273,\n",
       " 2851: 274,\n",
       " 3024: 275,\n",
       " 3210: 276,\n",
       " 3949: 277,\n",
       " 4518: 278,\n",
       " 5048: 279,\n",
       " 5181: 280,\n",
       " 5746: 281,\n",
       " 5764: 282,\n",
       " 5919: 283,\n",
       " 6238: 284,\n",
       " 6835: 285,\n",
       " 7899: 286,\n",
       " 7991: 287,\n",
       " 26409: 288,\n",
       " 70946: 289,\n",
       " 72378: 290,\n",
       " 21: 291,\n",
       " 32: 292,\n",
       " 45: 293,\n",
       " 52: 294,\n",
       " 58: 295,\n",
       " 106: 296,\n",
       " 125: 297,\n",
       " 126: 298,\n",
       " 162: 299,\n",
       " 171: 300,\n",
       " 176: 301,\n",
       " 190: 302,\n",
       " 215: 303,\n",
       " 222: 304,\n",
       " 232: 305,\n",
       " 247: 306,\n",
       " 265: 307,\n",
       " 319: 308,\n",
       " 342: 309,\n",
       " 345: 310,\n",
       " 348: 311,\n",
       " 351: 312,\n",
       " 357: 313,\n",
       " 368: 314,\n",
       " 417: 315,\n",
       " 450: 316,\n",
       " 475: 317,\n",
       " 492: 318,\n",
       " 509: 319,\n",
       " 538: 320,\n",
       " 539: 321,\n",
       " 588: 322,\n",
       " 595: 323,\n",
       " 599: 324,\n",
       " 708: 325,\n",
       " 759: 326,\n",
       " 800: 327,\n",
       " 892: 328,\n",
       " 898: 329,\n",
       " 899: 330,\n",
       " 902: 331,\n",
       " 904: 332,\n",
       " 908: 333,\n",
       " 910: 334,\n",
       " 912: 335,\n",
       " 920: 336,\n",
       " 930: 337,\n",
       " 937: 338,\n",
       " 1046: 339,\n",
       " 1057: 340,\n",
       " 1077: 341,\n",
       " 1079: 342,\n",
       " 1084: 343,\n",
       " 1086: 344,\n",
       " 1094: 345,\n",
       " 1103: 346,\n",
       " 1179: 347,\n",
       " 1183: 348,\n",
       " 1188: 349,\n",
       " 1199: 350,\n",
       " 1203: 351,\n",
       " 1211: 352,\n",
       " 1225: 353,\n",
       " 1250: 354,\n",
       " 1259: 355,\n",
       " 1266: 356,\n",
       " 1279: 357,\n",
       " 1283: 358,\n",
       " 1288: 359,\n",
       " 1304: 360,\n",
       " 1391: 361,\n",
       " 1449: 362,\n",
       " 1466: 363,\n",
       " 1597: 364,\n",
       " 1641: 365,\n",
       " 1719: 366,\n",
       " 1733: 367,\n",
       " 1734: 368,\n",
       " 1834: 369,\n",
       " 1860: 370,\n",
       " 1883: 371,\n",
       " 1885: 372,\n",
       " 1892: 373,\n",
       " 1895: 374,\n",
       " 1907: 375,\n",
       " 1914: 376,\n",
       " 1916: 377,\n",
       " 1923: 378,\n",
       " 1947: 379,\n",
       " 1966: 380,\n",
       " 1968: 381,\n",
       " 2019: 382,\n",
       " 2076: 383,\n",
       " 2109: 384,\n",
       " 2145: 385,\n",
       " 2150: 386,\n",
       " 2186: 387,\n",
       " 2203: 388,\n",
       " 2204: 389,\n",
       " 2282: 390,\n",
       " 2324: 391,\n",
       " 2336: 392,\n",
       " 2351: 393,\n",
       " 2359: 394,\n",
       " 2390: 395,\n",
       " 2467: 396,\n",
       " 2583: 397,\n",
       " 2599: 398,\n",
       " 2683: 399,\n",
       " 2712: 400,\n",
       " 2762: 401,\n",
       " 2763: 402,\n",
       " 2770: 403,\n",
       " 2791: 404,\n",
       " 2843: 405,\n",
       " 2874: 406,\n",
       " 2921: 407,\n",
       " 2926: 408,\n",
       " 2973: 409,\n",
       " 3044: 410,\n",
       " 3060: 411,\n",
       " 3079: 412,\n",
       " 3083: 413,\n",
       " 3160: 414,\n",
       " 3175: 415,\n",
       " 3204: 416,\n",
       " 3255: 417,\n",
       " 3317: 418,\n",
       " 3358: 419,\n",
       " 3365: 420,\n",
       " 3408: 421,\n",
       " 3481: 422,\n",
       " 3508: 423,\n",
       " 3538: 424,\n",
       " 3591: 425,\n",
       " 3788: 426,\n",
       " 3851: 427,\n",
       " 3897: 428,\n",
       " 3911: 429,\n",
       " 3967: 430,\n",
       " 3996: 431,\n",
       " 4002: 432,\n",
       " 4014: 433,\n",
       " 4020: 434,\n",
       " 4021: 435,\n",
       " 4027: 436,\n",
       " 4029: 437,\n",
       " 4033: 438,\n",
       " 4034: 439,\n",
       " 4074: 440,\n",
       " 4121: 441,\n",
       " 4144: 442,\n",
       " 4166: 443,\n",
       " 4226: 444,\n",
       " 4239: 445,\n",
       " 4246: 446,\n",
       " 4252: 447,\n",
       " 4260: 448,\n",
       " 4273: 449,\n",
       " 4308: 450,\n",
       " 4347: 451,\n",
       " 4381: 452,\n",
       " 4641: 453,\n",
       " 4741: 454,\n",
       " 4765: 455,\n",
       " 4881: 456,\n",
       " 4896: 457,\n",
       " 4902: 458,\n",
       " 4967: 459,\n",
       " 34: 460,\n",
       " 36: 461,\n",
       " 39: 462,\n",
       " 150: 463,\n",
       " 153: 464,\n",
       " 253: 465,\n",
       " 261: 466,\n",
       " 266: 467,\n",
       " 290: 468,\n",
       " 300: 469,\n",
       " 344: 470,\n",
       " 364: 471,\n",
       " 380: 472,\n",
       " 410: 473,\n",
       " 474: 474,\n",
       " 515: 475,\n",
       " 531: 476,\n",
       " 534: 477,\n",
       " 589: 478,\n",
       " 594: 479,\n",
       " 597: 480,\n",
       " 2: 481,\n",
       " 4: 482,\n",
       " 5: 483,\n",
       " 7: 484,\n",
       " 8: 485,\n",
       " 10: 486,\n",
       " 11: 487,\n",
       " 13: 488,\n",
       " 15: 489,\n",
       " 16: 490,\n",
       " 17: 491,\n",
       " 19: 492,\n",
       " 22: 493,\n",
       " 24: 494,\n",
       " 25: 495,\n",
       " 26: 496,\n",
       " 27: 497,\n",
       " 41: 498,\n",
       " 43: 499,\n",
       " 46: 500,\n",
       " 54: 501,\n",
       " 60: 502,\n",
       " 61: 503,\n",
       " 62: 504,\n",
       " 65: 505,\n",
       " 66: 506,\n",
       " 76: 507,\n",
       " 79: 508,\n",
       " 86: 509,\n",
       " 87: 510,\n",
       " 88: 511,\n",
       " 89: 512,\n",
       " 92: 513,\n",
       " 93: 514,\n",
       " 95: 515,\n",
       " 100: 516,\n",
       " 102: 517,\n",
       " 104: 518,\n",
       " 105: 519,\n",
       " 112: 520,\n",
       " 113: 521,\n",
       " 135: 522,\n",
       " 140: 523,\n",
       " 141: 524,\n",
       " 145: 525,\n",
       " 146: 526,\n",
       " 158: 527,\n",
       " 159: 528,\n",
       " 160: 529,\n",
       " 161: 530,\n",
       " 165: 531,\n",
       " 168: 532,\n",
       " 170: 533,\n",
       " 174: 534,\n",
       " 177: 535,\n",
       " 179: 536,\n",
       " 180: 537,\n",
       " 181: 538,\n",
       " 185: 539,\n",
       " 186: 540,\n",
       " 189: 541,\n",
       " 191: 542,\n",
       " 195: 543,\n",
       " 196: 544,\n",
       " 201: 545,\n",
       " 204: 546,\n",
       " 205: 547,\n",
       " 207: 548,\n",
       " 208: 549,\n",
       " 209: 550,\n",
       " 210: 551,\n",
       " 212: 552,\n",
       " 217: 553,\n",
       " 218: 554,\n",
       " 219: 555,\n",
       " 224: 556,\n",
       " 225: 557,\n",
       " 230: 558,\n",
       " 234: 559,\n",
       " 236: 560,\n",
       " 237: 561,\n",
       " 239: 562,\n",
       " 240: 563,\n",
       " 243: 564,\n",
       " 248: 565,\n",
       " 250: 566,\n",
       " 251: 567,\n",
       " 252: 568,\n",
       " 254: 569,\n",
       " 256: 570,\n",
       " 257: 571,\n",
       " 258: 572,\n",
       " 262: 573,\n",
       " 267: 574,\n",
       " 270: 575,\n",
       " 271: 576,\n",
       " 273: 577,\n",
       " 274: 578,\n",
       " 276: 579,\n",
       " 277: 580,\n",
       " 279: 581,\n",
       " 281: 582,\n",
       " 282: 583,\n",
       " 288: 584,\n",
       " 289: 585,\n",
       " 291: 586,\n",
       " 292: 587,\n",
       " 293: 588,\n",
       " 302: 589,\n",
       " 303: 590,\n",
       " 304: 591,\n",
       " 310: 592,\n",
       " 312: 593,\n",
       " 313: 594,\n",
       " 314: 595,\n",
       " 315: 596,\n",
       " 317: 597,\n",
       " 327: 598,\n",
       " 329: 599,\n",
       " 330: 600,\n",
       " 332: 601,\n",
       " 336: 602,\n",
       " 337: 603,\n",
       " 339: 604,\n",
       " 340: 605,\n",
       " 343: 606,\n",
       " 347: 607,\n",
       " 350: 608,\n",
       " 352: 609,\n",
       " 353: 610,\n",
       " 354: 611,\n",
       " 355: 612,\n",
       " 358: 613,\n",
       " 359: 614,\n",
       " 360: 615,\n",
       " 361: 616,\n",
       " 366: 617,\n",
       " 370: 618,\n",
       " 371: 619,\n",
       " 374: 620,\n",
       " 377: 621,\n",
       " 378: 622,\n",
       " 381: 623,\n",
       " 382: 624,\n",
       " 383: 625,\n",
       " 405: 626,\n",
       " 412: 627,\n",
       " 415: 628,\n",
       " 416: 629,\n",
       " 419: 630,\n",
       " 426: 631,\n",
       " 432: 632,\n",
       " 434: 633,\n",
       " 435: 634,\n",
       " 437: 635,\n",
       " 440: 636,\n",
       " 445: 637,\n",
       " 454: 638,\n",
       " 455: 639,\n",
       " 458: 640,\n",
       " 460: 641,\n",
       " 466: 642,\n",
       " 468: 643,\n",
       " 469: 644,\n",
       " 472: 645,\n",
       " 477: 646,\n",
       " 485: 647,\n",
       " 489: 648,\n",
       " 490: 649,\n",
       " 491: 650,\n",
       " 493: 651,\n",
       " 494: 652,\n",
       " 497: 653,\n",
       " 502: 654,\n",
       " 505: 655,\n",
       " 508: 656,\n",
       " 510: 657,\n",
       " 516: 658,\n",
       " 520: 659,\n",
       " 524: 660,\n",
       " 532: 661,\n",
       " 536: 662,\n",
       " 537: 663,\n",
       " 540: 664,\n",
       " 542: 665,\n",
       " 546: 666,\n",
       " 548: 667,\n",
       " 569: 668,\n",
       " 575: 669,\n",
       " 587: 670,\n",
       " 606: 671,\n",
       " 609: 672,\n",
       " 616: 673,\n",
       " 628: 674,\n",
       " 631: 675,\n",
       " 637: 676,\n",
       " 640: 677,\n",
       " 662: 678,\n",
       " 667: 679,\n",
       " 694: 680,\n",
       " 697: 681,\n",
       " 700: 682,\n",
       " 704: 683,\n",
       " 709: 684,\n",
       " 710: 685,\n",
       " 711: 686,\n",
       " 719: 687,\n",
       " 747: 688,\n",
       " 762: 689,\n",
       " 765: 690,\n",
       " 775: 691,\n",
       " 783: 692,\n",
       " 795: 693,\n",
       " 799: 694,\n",
       " 801: 695,\n",
       " 802: 696,\n",
       " 818: 697,\n",
       " 830: 698,\n",
       " 835: 699,\n",
       " 837: 700,\n",
       " 838: 701,\n",
       " 839: 702,\n",
       " 842: 703,\n",
       " 848: 704,\n",
       " 852: 705,\n",
       " 867: 706,\n",
       " 880: 707,\n",
       " 881: 708,\n",
       " 888: 709,\n",
       " 891: 710,\n",
       " 979: 711,\n",
       " 981: 712,\n",
       " 986: 713,\n",
       " 991: 714,\n",
       " 996: 715,\n",
       " 999: 716,\n",
       " 1004: 717,\n",
       " 1006: 718,\n",
       " 1061: 719,\n",
       " 1064: 720,\n",
       " 1082: 721,\n",
       " 750: 722,\n",
       " 924: 723,\n",
       " 1101: 724,\n",
       " 1246: 725,\n",
       " 1584: 726,\n",
       " 1610: 727,\n",
       " 1682: 728,\n",
       " 1784: 729,\n",
       " 1917: 730,\n",
       " 2671: 731,\n",
       " 2688: 732,\n",
       " 2701: 733,\n",
       " 2717: 734,\n",
       " 3114: 735,\n",
       " 3354: 736,\n",
       " 3623: 737,\n",
       " 3869: 738,\n",
       " 3916: 739,\n",
       " 3977: 740,\n",
       " 3994: 741,\n",
       " 4018: 742,\n",
       " 4223: 743,\n",
       " 4306: 744,\n",
       " 4310: 745,\n",
       " 4370: 746,\n",
       " 4643: 747,\n",
       " 4700: 748,\n",
       " 4844: 749,\n",
       " 4874: 750,\n",
       " 4886: 751,\n",
       " 4963: 752,\n",
       " 4993: 753,\n",
       " 4995: 754,\n",
       " 5218: 755,\n",
       " 5349: 756,\n",
       " 5378: 757,\n",
       " 5445: 758,\n",
       " 5459: 759,\n",
       " 5464: 760,\n",
       " 5502: 761,\n",
       " 5618: 762,\n",
       " 5816: 763,\n",
       " 5952: 764,\n",
       " 5989: 765,\n",
       " 5991: 766,\n",
       " 6333: 767,\n",
       " 6365: 768,\n",
       " 6534: 769,\n",
       " 6539: 770,\n",
       " 6863: 771,\n",
       " 6934: 772,\n",
       " 7143: 773,\n",
       " 7153: 774,\n",
       " 7155: 775,\n",
       " 7445: 776,\n",
       " 8207: 777,\n",
       " 8360: 778,\n",
       " 8368: 779,\n",
       " 8373: 780,\n",
       " 8528: 781,\n",
       " 8636: 782,\n",
       " 8665: 783,\n",
       " 8666: 784,\n",
       " 8783: 785,\n",
       " 8808: 786,\n",
       " 8865: 787,\n",
       " 8870: 788,\n",
       " 8907: 789,\n",
       " 8908: 790,\n",
       " 8949: 791,\n",
       " 8957: 792,\n",
       " 8958: 793,\n",
       " 8961: 794,\n",
       " 8965: 795,\n",
       " 8970: 796,\n",
       " 8972: 797,\n",
       " 8984: 798,\n",
       " 27741: 799,\n",
       " 30812: 800,\n",
       " 30816: 801,\n",
       " 31878: 802,\n",
       " 32029: 803,\n",
       " 32031: 804,\n",
       " 32296: 805,\n",
       " 32587: 806,\n",
       " 33162: 807,\n",
       " 33493: 808,\n",
       " 33794: 809,\n",
       " 33836: 810,\n",
       " 34048: 811,\n",
       " 34319: 812,\n",
       " 37741: 813,\n",
       " 38388: 814,\n",
       " 42002: 815,\n",
       " 45499: 816,\n",
       " 45517: 817,\n",
       " 45668: 818,\n",
       " 45730: 819,\n",
       " 46530: 820,\n",
       " 48783: 821,\n",
       " 48997: 822,\n",
       " 49272: 823,\n",
       " 49278: 824,\n",
       " 49286: 825,\n",
       " 49824: 826,\n",
       " 586: 827,\n",
       " 187: 828,\n",
       " 627: 829,\n",
       " 922: 830,\n",
       " 1037: 831,\n",
       " 1095: 832,\n",
       " 1674: 833,\n",
       " 1987: 834,\n",
       " 2011: 835,\n",
       " 2023: 836,\n",
       " 2300: 837,\n",
       " 2877: 838,\n",
       " 2901: 839,\n",
       " 3173: 840,\n",
       " 3328: 841,\n",
       " 3735: 842,\n",
       " 4131: 843,\n",
       " 4558: 844,\n",
       " 5447: 845,\n",
       " 5451: 846,\n",
       " 5481: 847,\n",
       " 5507: 848,\n",
       " 5841: 849,\n",
       " 5843: 850,\n",
       " 5872: 851,\n",
       " 5890: 852,\n",
       " 5891: 853,\n",
       " 5893: 854,\n",
       " 5902: 855,\n",
       " 5956: 856,\n",
       " 5962: 857,\n",
       " 5965: 858,\n",
       " 5988: 859,\n",
       " 6001: 860,\n",
       " 6044: 861,\n",
       " 1028: 862,\n",
       " 1088: 863,\n",
       " 1247: 864,\n",
       " 1307: 865,\n",
       " 3882: 866,\n",
       " 4447: 867,\n",
       " 5066: 868,\n",
       " 5377: 869,\n",
       " 5620: 870,\n",
       " 5943: 871,\n",
       " 5957: 872,\n",
       " 6155: 873,\n",
       " 6266: 874,\n",
       " 6377: 875,\n",
       " 6535: 876,\n",
       " 6942: 877,\n",
       " 7149: 878,\n",
       " 7151: 879,\n",
       " 7154: 880,\n",
       " 7169: 881,\n",
       " 7293: 882,\n",
       " 7375: 883,\n",
       " 7451: 884,\n",
       " 7458: 885,\n",
       " 8529: 886,\n",
       " 8533: 887,\n",
       " 8869: 888,\n",
       " 8969: 889,\n",
       " 30749: 890,\n",
       " 31433: 891,\n",
       " 31685: 892,\n",
       " 33145: 893,\n",
       " 33679: 894,\n",
       " 40629: 895,\n",
       " 40819: 896,\n",
       " 41285: 897,\n",
       " 47099: 898,\n",
       " 51662: 899,\n",
       " 51705: 900,\n",
       " 51834: 901,\n",
       " 54286: 902,\n",
       " 56367: 903,\n",
       " 56949: 904,\n",
       " 58047: 905,\n",
       " 59333: 906,\n",
       " 59421: 907,\n",
       " 60397: 908,\n",
       " 60950: 909,\n",
       " 61250: 910,\n",
       " 63113: 911,\n",
       " 63992: 912,\n",
       " 64969: 913,\n",
       " 66203: 914,\n",
       " 68954: 915,\n",
       " 69406: 916,\n",
       " 69844: 917,\n",
       " 70183: 918,\n",
       " 70293: 919,\n",
       " 71579: 920,\n",
       " 72011: 921,\n",
       " 72330: 922,\n",
       " 72407: 923,\n",
       " 72720: 924,\n",
       " 72737: 925,\n",
       " 72998: 926,\n",
       " 73017: 927,\n",
       " 74450: 928,\n",
       " 77841: 929,\n",
       " 78772: 930,\n",
       " 79091: 931,\n",
       " 80549: 932,\n",
       " 81784: 933,\n",
       " 81845: 934,\n",
       " 81847: 935,\n",
       " 82167: 936,\n",
       " 82499: 937,\n",
       " 84374: 938,\n",
       " 86548: 939,\n",
       " 87222: 940,\n",
       " 88163: 941,\n",
       " 88810: 942,\n",
       " 91104: 943,\n",
       " 92259: 944,\n",
       " 94070: 945,\n",
       " 95167: 946,\n",
       " 95449: 947,\n",
       " 95510: 948,\n",
       " 95543: 949,\n",
       " 96079: 950,\n",
       " 97024: 951,\n",
       " 97938: 952,\n",
       " 98203: 953,\n",
       " 103335: 954,\n",
       " 103339: 955,\n",
       " 104374: 956,\n",
       " 105211: 957,\n",
       " 106489: 958,\n",
       " 106696: 959,\n",
       " 107141: 960,\n",
       " 109374: 961,\n",
       " 109853: 962,\n",
       " 112006: 963,\n",
       " 113275: 964,\n",
       " 113394: 965,\n",
       " 119145: 966,\n",
       " 129428: 967,\n",
       " 136020: 968,\n",
       " 137595: 969,\n",
       " 140110: 970,\n",
       " 44: 971,\n",
       " 376: 972,\n",
       " 511: 973,\n",
       " 529: 974,\n",
       " 1100: 975,\n",
       " 1358: 976,\n",
       " 1370: 977,\n",
       " 1385: 978,\n",
       " 1438: 979,\n",
       " 1518: 980,\n",
       " 1586: 981,\n",
       " 1604: 982,\n",
       " 1608: 983,\n",
       " 1616: 984,\n",
       " 1687: 985,\n",
       " 1693: 986,\n",
       " 1721: 987,\n",
       " 1840: 988,\n",
       " 1882: 989,\n",
       " 1918: 990,\n",
       " 2002: 991,\n",
       " 2027: 992,\n",
       " 1357: 993,\n",
       " 1405: 994,\n",
       " 1876: 995,\n",
       " 2072: 996,\n",
       " 2100: 997,\n",
       " 2421: 998,\n",
       " 2485: 999,\n",
       " ...}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the adjacency matrix based on user ratings\n",
    "user_ids = torch.LongTensor([user_mapping[i] for i in ratings['userId']])\n",
    "item_ids = torch.LongTensor([item_mapping[i] for i in ratings['movieId']])\n",
    "edge_index = torch.stack((user_ids, item_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training, validation, and test adjacency matrices\n",
    "train_index, test_index = train_test_split(range(len(ratings)), test_size=0.2, random_state=0)\n",
    "val_index, test_index = train_test_split(test_index, test_size=0.5, random_state=0)\n",
    "\n",
    "train_edge_index = edge_index[:, train_index]\n",
    "val_edge_index = edge_index[:, val_index]\n",
    "test_edge_index = edge_index[:, test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a function to sample random mini batches of BATCH_SIZE size.\n",
    "def sample_mini_batch(edge_index):\n",
    "    # Generate BATCH_SIZE random indices\n",
    "    index = np.random.choice(range(edge_index.shape[1]), size=BATCH_SIZE)\n",
    "\n",
    "    # Generate negative sample indices\n",
    "    edge_index = structured_negative_sampling(edge_index)\n",
    "    edge_index = torch.stack(edge_index, dim=0)\n",
    "    \n",
    "    user_index = edge_index[0, index]\n",
    "    pos_item_index = edge_index[1, index]\n",
    "    neg_item_index = edge_index[2, index]\n",
    "    \n",
    "    return user_index, pos_item_index, neg_item_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 20\n",
    "LAMBDA = 1e-6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LightGCN(nn.Module):\n",
    "    def __init__(self, num_users, num_items, num_layers=4, dim_h=64):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.num_users = num_users\n",
    "        self.num_items = num_items\n",
    "        self.num_layers = num_layers\n",
    "        self.emb_users = nn.Embedding(num_embeddings=self.num_users, embedding_dim=dim_h)\n",
    "        self.emb_items = nn.Embedding(num_embeddings=self.num_items, embedding_dim=dim_h)\n",
    "\n",
    "        self.convs = nn.ModuleList(LGConv() for _ in range(num_layers))\n",
    "\n",
    "        nn.init.normal_(self.emb_users.weight, std=0.01)\n",
    "        nn.init.normal_(self.emb_items.weight, std=0.01)\n",
    "\n",
    "    def forward(self, edge_index):\n",
    "        emb = torch.cat([self.emb_users.weight, self.emb_items.weight])\n",
    "        embs = [emb]\n",
    "\n",
    "        for conv in self.convs:\n",
    "            emb = conv(x=emb, edge_index=edge_index)\n",
    "            embs.append(emb)\n",
    "\n",
    "        emb_final = 1/(self.num_layers+1) * torch.mean(torch.stack(embs, dim=1), dim=1)\n",
    "\n",
    "        emb_users_final, emb_items_final = torch.split(emb_final, [self.num_users, self.num_items])\n",
    "\n",
    "        return emb_users_final, self.emb_users.weight, emb_items_final, self.emb_items.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bpr_loss(emb_users_final, emb_users, emb_pos_items_final, emb_pos_items, emb_neg_items_final, emb_neg_items):\n",
    "    reg_loss = LAMBDA * (emb_users.norm().pow(2) +\n",
    "                        emb_pos_items.norm().pow(2) +\n",
    "                        emb_neg_items.norm().pow(2))\n",
    "\n",
    "    pos_ratings = torch.mul(emb_users_final, emb_pos_items_final).sum(dim=-1)\n",
    "    neg_ratings = torch.mul(emb_users_final, emb_neg_items_final).sum(dim=-1)\n",
    "\n",
    "    bpr_loss = torch.mean(torch.nn.functional.softplus(pos_ratings - neg_ratings))\n",
    "    # bpr_loss = torch.mean(torch.nn.functional.logsigmoid(pos_ratings - neg_ratings))\n",
    "\n",
    "    return -bpr_loss + reg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_items(edge_index):\n",
    "    user_items = dict()\n",
    "    for i in range(edge_index.shape[1]):\n",
    "        user = edge_index[0][i].item()\n",
    "        item = edge_index[1][i].item()\n",
    "        if user not in user_items:\n",
    "            user_items[user] = []\n",
    "        user_items[user].append(item)\n",
    "    return user_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_recall_at_k(items_ground_truth, items_predicted):\n",
    "    num_correct_pred = np.sum(items_predicted, axis=1)\n",
    "    num_total_pred = np.array([len(items_ground_truth[i]) for i in range(len(items_ground_truth))])\n",
    "\n",
    "    recall = np.mean(num_correct_pred / num_total_pred)\n",
    "\n",
    "    return recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_ndcg_at_k(items_ground_truth, items_predicted):\n",
    "    test_matrix = np.zeros((len(items_predicted), K))\n",
    "\n",
    "    for i, items in enumerate(items_ground_truth):\n",
    "        length = min(len(items), K)\n",
    "        test_matrix[i, :length] = 1\n",
    "    \n",
    "    max_r = test_matrix\n",
    "    idcg = np.sum(max_r * 1. / np.log2(np.arange(2, K + 2)), axis=1)\n",
    "    dcg = items_predicted * (1. / np.log2(np.arange(2, K + 2)))\n",
    "    dcg = np.sum(dcg, axis=1)\n",
    "    idcg[idcg == 0.] = 1.\n",
    "    ndcg = dcg / idcg\n",
    "    ndcg[np.isnan(ndcg)] = 0.\n",
    "    \n",
    "    return np.mean(ndcg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrapper function to get evaluation metrics\n",
    "def get_metrics(model, edge_index, exclude_edge_indices):\n",
    "\n",
    "    ratings = torch.matmul(model.emb_users.weight, model.emb_items.weight.T)\n",
    "\n",
    "    for exclude_edge_index in exclude_edge_indices:\n",
    "        user_pos_items = get_user_items(exclude_edge_index)\n",
    "        exclude_users = []\n",
    "        exclude_items = []\n",
    "        for user, items in user_pos_items.items():\n",
    "            exclude_users.extend([user] * len(items))\n",
    "            exclude_items.extend(items)\n",
    "        ratings[exclude_users, exclude_items] = -1024\n",
    "\n",
    "    # get the top k recommended items for each user\n",
    "    _, top_K_items = torch.topk(ratings, k=K)\n",
    "\n",
    "    # get all unique users in evaluated split\n",
    "    users = edge_index[0].unique()\n",
    "\n",
    "    test_user_pos_items = get_user_items(edge_index)\n",
    "\n",
    "    # convert test user pos items dictionary into a list\n",
    "    test_user_pos_items_list = [test_user_pos_items[user.item()] for user in users]\n",
    "\n",
    "    # determine the correctness of topk predictions\n",
    "    items_predicted = []\n",
    "    for user in users:\n",
    "        ground_truth_items = test_user_pos_items[user.item()]\n",
    "        label = list(map(lambda x: x in ground_truth_items, top_K_items[user]))\n",
    "        items_predicted.append(label)\n",
    "\n",
    "    recall = compute_recall_at_k(test_user_pos_items_list, items_predicted)\n",
    "    ndcg = compute_ndcg_at_k(test_user_pos_items_list, items_predicted)\n",
    "\n",
    "    return recall, ndcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrapper function to evaluate model\n",
    "def test(model, edge_index, exclude_edge_indices):\n",
    "    emb_users_final, emb_users, emb_items_final, emb_items = model.forward(edge_index)\n",
    "    user_indices, pos_item_indices, neg_item_indices = structured_negative_sampling(edge_index, contains_neg_self_loops=False)\n",
    "\n",
    "    emb_users_final, emb_users = emb_users_final[user_indices], emb_users[user_indices]\n",
    "\n",
    "    emb_pos_items_final, emb_pos_items = emb_items_final[pos_item_indices], emb_items[pos_item_indices]\n",
    "    emb_neg_items_final, emb_neg_items = emb_items_final[neg_item_indices], emb_items[neg_item_indices]\n",
    "\n",
    "    loss = bpr_loss(emb_users_final, emb_users, emb_pos_items_final, emb_pos_items, emb_neg_items_final, emb_neg_items).item()\n",
    "\n",
    "    recall, ndcg = get_metrics(model, edge_index, exclude_edge_indices)\n",
    "\n",
    "    return loss, recall, ndcg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model = LightGCN(num_users, num_items)\n",
    "model = model.to(device)\n",
    "edge_index = edge_index.to(device)\n",
    "train_edge_index = train_edge_index.to(device)\n",
    "val_edge_index = val_edge_index.to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Train loss: -0.69910 | Val loss: -0.68853 | Val recall@20: 0.10792 | Val ndcg@20: 0.11027\n",
      "Epoch 5 | Train loss: -1.32814 | Val loss: -0.43909 | Val recall@20: 0.10471 | Val ndcg@20: 0.10883\n",
      "Epoch 10 | Train loss: -3.50767 | Val loss: -0.10342 | Val recall@20: 0.10729 | Val ndcg@20: 0.11250\n",
      "Epoch 15 | Train loss: -6.82942 | Val loss: 0.20109 | Val recall@20: 0.10906 | Val ndcg@20: 0.11416\n",
      "Epoch 20 | Train loss: -10.87928 | Val loss: 0.52200 | Val recall@20: 0.10737 | Val ndcg@20: 0.11353\n",
      "Epoch 25 | Train loss: -16.71166 | Val loss: 0.86660 | Val recall@20: 0.11200 | Val ndcg@20: 0.11478\n",
      "Epoch 30 | Train loss: -21.90753 | Val loss: 1.26435 | Val recall@20: 0.11002 | Val ndcg@20: 0.11367\n",
      "CPU times: user 12min 18s, sys: 1min 41s, total: 14min\n",
      "Wall time: 2min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "n_batch = int(len(train_index)/BATCH_SIZE)\n",
    "\n",
    "for epoch in range(31):\n",
    "    model.train()\n",
    "\n",
    "    for _ in range(n_batch):\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        emb_users_final, emb_users, emb_items_final, emb_items = model.forward(train_edge_index)\n",
    "\n",
    "        user_indices, pos_item_indices, neg_item_indices = sample_mini_batch(train_edge_index)\n",
    "        \n",
    "        emb_users_final, emb_users = emb_users_final[user_indices], emb_users[user_indices]\n",
    "        emb_pos_items_final, emb_pos_items = emb_items_final[pos_item_indices], emb_items[pos_item_indices]\n",
    "        emb_neg_items_final, emb_neg_items = emb_items_final[neg_item_indices], emb_items[neg_item_indices]\n",
    "\n",
    "        train_loss = bpr_loss(emb_users_final, emb_users, emb_pos_items_final, emb_pos_items, emb_neg_items_final, emb_neg_items)\n",
    "\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    if epoch % 5 == 0:\n",
    "        model.eval()\n",
    "        val_loss, recall, ndcg = test(model, val_edge_index, [train_edge_index])\n",
    "        print(f\"Epoch {epoch} | Train loss: {train_loss.item():.5f} | Val loss: {val_loss:.5f} | Val recall@{K}: {recall:.5f} | Val ndcg@{K}: {ndcg:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 3.45198 | Test recall@20: 0.12195 | Test ndcg@20: 0.12614\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_recall, test_ndcg = test(model, test_edge_index.to(device), [train_edge_index, val_edge_index])\n",
    "\n",
    "print(f\"Test loss: {test_loss:.5f} | Test recall@{K}: {test_recall:.5f} | Test ndcg@{K}: {test_ndcg:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_title = pd.Series(movies['title'].values, index=movies.movieId).to_dict()\n",
    "user_pos_items = get_user_items(edge_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import requests\n",
    "\n",
    "def recommend(user_id, num_recs):\n",
    "    #print(user_mapping)\n",
    "    if user_id not in user_mapping:\n",
    "        print(\"User not found.\")\n",
    "        return None\n",
    "    #print(f\"The \")\n",
    "    user = user_mapping[user_id]\n",
    "    emb_user = model.emb_users.weight[user]\n",
    "    ratings = model.emb_items.weight @ emb_user\n",
    "\n",
    "    values, indices = torch.topk(ratings, k=100)\n",
    "\n",
    "    ids = [index.cpu().item() for index in indices if index in user_pos_items[user]][:num_recs]\n",
    "    movies = [list(item_mapping.keys())[list(item_mapping.values()).index(movie)] for movie in ids]\n",
    "    titles = [movie_title[id] for id in movies]\n",
    "\n",
    "    print(f'Favorite movies from user nÂ°{user_id}:')\n",
    "    for i in range(len(movies)):\n",
    "        print(f'- {titles[i]}')\n",
    "\n",
    "    ids = [index.cpu().item() for index in indices if index not in user_pos_items[user]][:num_recs]\n",
    "    movies = [list(item_mapping.keys())[list(item_mapping.values()).index(movie)] for movie in ids]\n",
    "    titles = [movie_title[id] for id in movies]\n",
    "\n",
    "    print(f'\\nRecommended movies for user nÂ°{user_id}')\n",
    "    for i in range(num_recs):\n",
    "        print(f'- {titles[i]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Favorite movies from user nÂ°114:\n",
      "- Star Wars: Episode IV - A New Hope (1977)\n",
      "- Silence of the Lambs, The (1991)\n",
      "- Star Wars: Episode VI - Return of the Jedi (1983)\n",
      "- Shrek (2001)\n",
      "- Incredibles, The (2004)\n",
      "\n",
      "Recommended movies for user nÂ°114\n",
      "- Forrest Gump (1994)\n",
      "- Shawshank Redemption, The (1994)\n",
      "- Pulp Fiction (1994)\n",
      "- Matrix, The (1999)\n",
      "- Jurassic Park (1993)\n"
     ]
    }
   ],
   "source": [
    "recommend(114, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(model, '../../Web App/entire_model.pt', _use_new_zipfile_serialization=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
